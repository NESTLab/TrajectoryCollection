{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lf7huAiYp-An"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "YHz2D-oIqBWa"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x44FFES-r6y0"
   },
   "source": [
    "# Federated Learning for Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LcC1AwjoqfR"
   },
   "outputs": [],
   "source": [
    "# NOTE: If you are running a Jupyter notebook, and installing a locally built\n",
    "# pip package, you may need to edit the following to point to the '.whl' file\n",
    "# on your local filesystem.\n",
    "\n",
    "# !pip install --quiet tensorflow_federated\n",
    "# !pip install --quiet tf-nightly\n",
    "\n",
    "# NOTE: Jupyter requires a patch to asyncio.\n",
    "# !pip install --upgrade nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7569,
     "status": "ok",
     "timestamp": 1570299845080,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "ZjDQysatrc2S",
    "outputId": "899234fb-8d67-4f85-b4e5-18d30f509824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World!'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import six\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load distributed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/flocking**.dat' #foraging_20191211_213418.dat' #foraging**.dat'\n",
    "\n",
    "samples = {}\n",
    "cnt = 0\n",
    "\n",
    "for filename in glob.iglob(path):\n",
    "    for line in open(filename):\n",
    "        data = line.split(',')\n",
    "        if len(data) == 6:\n",
    "            rid = data[0]\n",
    "            x1 = float(data[2])\n",
    "            x2 = float(data[3])\n",
    "            if rid in samples.keys():\n",
    "                last_key = list(samples[rid].keys())[-1]\n",
    "                samples[rid][last_key].append((x1, x2))\n",
    "            else:\n",
    "                samples.update({rid: {}})\n",
    "                samples[rid].update({0: []})\n",
    "        else:\n",
    "            last_key = list(samples[rid].keys())[-1]\n",
    "            samples[rid][last_key + 1] = []\n",
    "            \n",
    "\n",
    "# print(samples['10'][2])\n",
    "# print(samples['1'].keys())\n",
    "# print(samples.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2df5QdZZnnv8/tHwlpkkgSdgOSpEU5e4hkdgYiIWR1OBqJSI6zwDjDmEadnDU4sI7ouPThR+htIJOJsp4sY0bTKCMEVsfRZnWDLtCjc2SggUk7sxsMs8pyiI3IigkGCIaQ7nf/eG+lb1fXW/VW1Vs/7/dzTp/uvrdu1XvfW/dbTz3v80OUUiCEEFJdGkUPgBBCSDoo5IQQUnEo5IQQUnEo5IQQUnEo5IQQUnE6izjookWLVG9vbxGHJoSQyjI2NvYrpdTJ/scLEfLe3l7s2bOniEMTQkhlEZH9QY/TtUIIIRWHQk4IIRWHQk4IIRWHQk4IIRWHQk4IIRWHQk4IIRWHQk5SMzYE/NXbgR3L9d+EkHwpJI6c5M+WHuDYa/rvFRuAS+9xs9/tvcChlsjW3VcCL/1fYO02N/snhERDi7wNaBVxANh7LzDcl26fY0PAYGO6iHs88llgfDTd/gkh9lDI24BWEffYe2/y/d12ira8EdKT5Nm/T75/Qkg86FppAzrnBIt5XIb77C8AvRekPx4hxA5a5DVkbAjYtW5q4fGGw8Hbbe+13+fWeXYiLp3AxkeBJavt900ISQct8poxNtR0ewB45kFg5Dqg/0DwtkH+bT9xrHCXi6iEEHso5DVj98en/3/koLa8G13A5Bv2+xkbAu6/ClAT0dt2zjFb/YSQ7KFrpW4ELEAe2g9sPhq8+baFMx/b3qutehsRX7GBIk5I0dAirxkmy3tQgrc/cnDq77Eh4P4/AdRk9HFmLzC7bAgh+UKLvGaYLO8ovJBCGxFfcy1FnJAyQYu8hgwoswUehO2285cB1zybaEiEkAyhRV5TTj3X4c4EWL8zWMTvWAXc0qV/E0KKgUJeUz72OJx8uqdfCAxMAudsmvncHauA558AJo/p33HuAggh7qCQ15gBi6gTEx2ztIvmigfM2zz/xMzHtvQkPyYhJBkU8pozEFIPxcSKDcCNR5Idz0UpAEJIPLjYWTLGR4Gv/q4OIXSRaDPSb79t3JDC+cvsskMJIdlCIS8Rren1gLZut/TYibkL//SsufG2v+ZZ+sUJKQN0rZQEv4h72LgqXImpK+ua4k5IvlDIS8D4aLCIA9q9QgghYVDIS8Cd55ufy7uOSZzStoCOL68z46PAw1vZ8YiUGwp5wYS5IWwiTmI1O7b4tOO6V4Liy4H0reTKwHCfvsh+/3r9m2JOygqFvEDSivjxlmshNLr0vgaUjitvdEXv14VgpWklVwaCGmnc+/5ixkJIFIxaKYg0Ij7SrxscR3H6hTMTejYfjV6MvOsC4MbXo/dfV0zz8/qvk+9zuA/Y+zUAAUXJGp3A2/+QTTlIcijkBRAmpBsfDX/ttoXTS88GkbbE7ETMCopxi3SVmbD3MX9Zsn1GdVmaPKafD72LEeDUdzRLLxDig0KeM4Mhzqz1O829Lm1brq3fafZbe9gI7/hovL6b/n0mySgtmqg5SVr58affS/a6aSi7ejbSCVy8I/ocIPVClMr/G7dy5Uq1Z8+e3I9bNIMdCLy1BnSN77XbZj4+Pgr89Tuju/UkKTE7NgTs+5bu7emno7u93CtRApnmwhSn72lenHourfsqIiJjSqmV/sdpkefEzZ0wiviKDcEivmM58KunInYswMZHknWtP2eT/rntFODwC9Ofi+teqTJZijgw5fs2+ciLINC6F2DFh+irryKpLXIRmQ3ghwBmQV8YvqmUGgh7TbtZ5LfOBiYM1m2QJW7K8vTj0qoKEjMbN02VsZnnrF1EY0PAyHXR6x55smIDxbysmCxyF0IuAHqUUq+KSBeAfwDwSaXUY6bXtJOQb+kxp9kHRZUEWcd+suhab7JKq+jrtsGrpW6i0ZW8bV4W7FoHPPMQAptrZ0HXicAVDya70yPZkZlrRekrwavNf7uaPzX9+scjTMTnL5su4rYhhXlbS9sW1q8/59Z5wNFXzM/3LAY+84v8xmNDWF14j+297urlvPGqToLa+Gi0mB8/zxvA+i/W+y6urDjxkYtIB4AxAG8DsEMpNeOGX0Q2AdgEAEuXLnVx2FKzdZ5ZxHsWT1+YjBIWIPuu9aZIliMH9WJdXW61wxacAfOicxWwWeweGwLuvyp68dzj2b83C/mMUNjJKVcVxTxfnEatiMibANwH4BNKqSdN29XdtTLYgPGepHsucN3L+m9bKzwvX3VUfHvVb7OzXtSsMqYLXNDnHmX5B7kMiRtyiVpRSv1aRH4A4H0AjEJeZ7b0INSxdPQV++SZRWcCV+9zMiwrTj3X7De+83x3QtcqBEnCJpNAETcz3IdAEe9ZPF3EbcMol1/mbGjEktS1VkTk5KYlDhE5AcB7AfxL2v1WFZetzibeyLdQU1QEjNeP85ZuLYyDou8+4hTu8ltzh/Zn3+eTIh6OSZy9dYKxIT2HNiK+YgPdKkXgwiI/BcBdTT95A8A3lFK7Hey3knTOcSfmLz1tKHErwElvBS65O193x7HXAkRRab/o7ivtFmIP/Sx4v3esyiZBhSIezh2rgh8/9Vz9O07phbqHq5YZZnZmQFi0Spa4EKWosDwbwuLbw/yrLoUgMkZcgIGSJOcUiUmoG126b6wNzBLNj8ziyJNQdyH3KCI124WYuyqAZfJ/py3fG0XUxahjFnDjkfTHqTpWmcMh5LW+QaZgin7O2FjlHbMACDBRU1E5tF+Ltj90Mqxo16CkE/OoUE6KzxRJRTzrUFgSHwp5BthYtFHxyiP9wGO3FyPyrsvSHjmo99eakZqFmNc5Rtw1t50S/zVZZBQTN9RWyKNur7Na5Lo5YkZt/Ylrt00XHRsLP6qWuS1xvuTrd9rXCvEWS71F0RUbzK6nwQ7d0cgWLmrGI6oMxDQa8T4Lkj+1bPVms2CXVSOEqIy5w/8v3v5G+vVYQ0W8w13CzthQvC/57iv1bfaAsm+8sPfeqWzRzjmGjSbNERV+KOLxiHuhpoiXn1oK+Qs/Ku7Y0hH+vOc3tom93rYwOvPz1HOBgWPuwhBtqi768YT0mme1aHqha2F4zRbCbtVtomco4vbcsUrPV9SFutHZFHDFcMKqUEshX3x2cce+6Vi0mANaME0i5Fnhoe6KphXuMuwrid/UY+u8qb8/9rgWgTXXmrc/46Kpv8PENqyjEkXcjl3r9FxFXhhFf2ab36CAV41aCvnHHo+2CrP8kt90TO9/9oLobQelmSLdZOu8/K1wINylsn5n9OuPvjL9fQDaxz+gZr4+KHHI+Hmo4HUHing0nkEQ1AHKz+kX6rh6LgZXE8aRZ4xtk4hFZ2bbDSgKkzB6STpxYo7ThKeZxuFFTETF5petjnhR2DTpBljgqmowIahg0taKzjL+2RQR4xfkW7rts/2Sirnthc/lMeuGzUU374JsxA1MCCoYT4STRMtkWcNiuM8cEXPGRcmje7zYcSsEWP+lqR6ipobQYdCynOLA/zE/V8amGSQ9tMgLwPa2Nw+rKaswzDypQ610lwRZ5I1O4P07uIhZdUwWeS0XO8uO7e3/KRlG33ilSavOgMpOxL1yvbd0Z7P/rLh6nzYCAL1mwEiU+kPXioGsmxHblLv1FvVctFkb7gOe/Lp9i68qkGVkSmuXp8k3tJhXaRGV/u/2gkIeQJil2vpcGiG54bCdRewlzsQhjzotYen1ebGlJ5vaHyP9mNHlyXaRl5AioJCnIG2lPpviVK2JM0GMjwL3fQR46afJxxGFqT7MpfcU65459pqOBvJH86S92Nr0US0Lu9YBP3sYWPpOLva2MxTygvGEJmgBNChxZtc64JmHENoXNC02nX481u9MHi7ogkP79eKe50rwX1jiXmxbM1Rb8XzOZWLXuqnonmce1P+3k5i3Vrts99BTCnkLRVqXQSfh2JB9hEtakt5ZnLMJeGx7ugYFafnVU26aeIz0m2uZl9Hn7A/RjBuyWVWC8hmOHNTflXYVcwo5kgu468W2LK3tRicweSz4udMvTLfvq/fFSxbKAhf+epNLxaZEAcmeKKMmD4OnrLS9kCcRcRcCPjZkX8c7CbMXAGu3ToWcDYYU8nJxO775aHnDGW1cDjuWBz/es5hhe0Vj20fWprZRXWl7IbclTYr88QXJp5GZtf32PzT7tYf7YOyc4/KuYuOjwJ3nR2/n+eDzEv5nHtSfgSnefHzU7BpiFmRxxGkETh85CSVRy7EsBUqAk94KXHK3fSKMye3g2oKJMx5bV0hoidsY83zn+eZ9mS4+YWV4SXbEqbfDImkaCrkBWwG/dTYw8XpGg2gA3XOAd1yVvLxomNhlYcG47vcZRvfc8EbLfoKSerb3Bm/bOSf7kq7+BVqW3o3uu9oK52uKWgp5kJCYXCN+4YlzcrgWcWkAb1nrLoQsrFVall+CvMQ8jogDejG2NbJhbMhckTLrJsNBUTZp8xKqTJyoozjhse1C7YTcJCBeizWP1i9M0i9PWhHvPAFY9Qmz5ed/L3HHafIv2rRiS4sLMc9i8erIwakkItPt+4oN7o/rx5Sxm5eYu8pQTkscAc+ylHPVqZ2Q2zIo9h3tXRC1IOknSATjfMnDRDSv9+yNNWmMd1aLV4f2hxfCysPaO+Mi85xkLeZpk6ZcMNIPPPI5WC3+t/tCpg1tK+SAtlizPold79tmvCa/L5D/FzZpQpONVZym3osp5j2v+bn0Hm2Vm+Ymq/My7NzIg/FR4K73ABO/id7W6wpFoqldGds8o0z8xxpQM3+yIGq8Jr9vHi6DVgY7ksfJ21jFl96j39PsBfp32vmevyzd6+PSf0BHXZjIYp0hTZeqtOxYriOEokS80aU/S4q4PbUTciCZkKYR8yxF20SS8ea5QDQoMEcfSHRo3651dse59B4tiN572/io7QhnUoT/dfNRhH4Lwz5n/4Un6kJkSnrqmBX+urTcsUq/j6gyDo1OnUXLcML41FLIWylKaNNiM95B0ZEXfjrnJNufK8LERzp0t/aoCoNeEk9clqxOdudR5PkxMIFEYn7Ns03xFruFQJOQ3phRuePhPj32qKQeabD5RVrastVb1k0jXBNVxyRo0dZrqJy3nzHqTmFAxavLkvQzidvsugw9P6NiqNOcn6YsySwSauIsZDKUMB6ZtXoTkSUi8gMR2SciPxaRT6bdZ9YEfiFKfG+y+Wh4KN7zT+hFxVZuOJy/n9FGxO9YFa+4VtLFuWueDb4zMZH0DiCKkX7g9jOazSoiGMiwe5PJKnYt4tt7m3dbESK+6Ex9PlDE3eBCvo4B+DOl1HIA5wG4WkQM3rjyMKAw9e4b2X6JXNB/INxlcOSgTlAqgsj+nw093yP9ZkEx+bbTLM7dcBixznCbOjFxGOnXovbS0/r3YKNZ9yaELO4KjYlhjo2XXeuiP685J+vPuoxlgauMc9eKiHwbwBeUUg+ZtinatVJ1IkUzg4uSKYEkqrCR59oJq5/huYZM26QVt7gLw67E9C/eBLx+KOAJAVZ8KNwa9buf0owpL1filjnAMUNESucJwIf/LrtG2e1CZq4V30F6AfwOgBkpJyKySUT2iMieF1980eVh244BFRK2Nqm/uC7dBEEJJIB254SJ+PxlWsR3rTOLuHRM+ffP2TQz8sJFFmrcSJabHWVXiOkConT8+6CYo3M2H812oT4s7DEpS9858zFvIfOG1yjiWeJMyEXkRADfAnCNUupl//NKqSGl1Eql1MqTTz7Z1WEBaL/coEz9tANRfvM7z7fzyyZlS094jPj6ndpPvaUnvHPNTb5mF9c8q8W70eku8zZuJIuacJM4YxOB8cyD+pwNq4uTBVmE+F3xQLNJSUN/fis2ADdNZF98jDhyrYhIF4DdAB5QSn0+anuXrpWqRaC4Zsfy8PjctGIYN/oDmJr7204BDr9g3i7viIW472X9zvThcCP9wCO3wbqi39zTgA9+w6316v8cehazznpVyTJqRQB8BcBTNiLuknaxvsO4el+4tfn8E/qLnJSkIj42FC7i0pF/xELchB8XTaXXbtNrFmuuBRDSpcnjlef03dStJwTnCCThM7/Q4g1QxOtKaotcRP4dgIcB7MWU3XG9Uuq7ptektchtBLxdLHKP8dHwqIuk8eSmksBBAt865zahiEVQVGs/j7Eh4H9+Ssf42yCdwPmfpnuCaDKzyJVS/6CUEqXUbymlfrv5YxTxtFDEg1my2hdS6ePYa/EX8UyWvOfH9uicE0/Eq9Z5x2WhqXM26Qvqxkd1KF4U6lgzdFGAzy/JJtadVJ9KZXZSxO3YOi+86cLGR+18sEHz3XmCjkCI85ppiE7RLwpXBdJcEqc3pUf3PODCzzGlvd0wWeSVKWNLEbfnupfDF/buPD/5QuOH/y7V0ICAhhNxa7WnogHrhce88Bajd60Lj/Bp5ejL2oe/+0q93nDW5cySbGdKnJgeD4r4dPzuDz977zVXwwPMz2URCzx5bCqu+vhPI5uQvPVf9D1Qom/AFQ/o8zhu0S81MTV/N3dEZ4+S+lEZ10q7hxkmxUsTDyNoDoPmu+tE4PoQl00eUUQnvQ245G77C8pwn27gcMZFUxbr2BCw71vA8su0a6Ksd3sj/cBjtwMTKaoT5tkFi2SPybVSGSEH0vewbFeiIlqAmXMZJG5RvvUiw0H9gnVzp7ZUWwlzJ9mOvaiuNcN9wN6vIZVbKIsYdZIvtRByko4gcWslKpEn7MLplc0N2+/YEDByXfKuQWnpngdcF1T7BOG1YEwUZUi4EPWuHmDd57lYWjUo5ARAuOCGEdYAN8x9E1Xne3wUuO8jwEs/jT+mJIS9jyRiDhTrvhgbAh78THiUUhRcLK0OFHJyHNdJMWH7S2q17loHPPMQrJoTpEU6gYt3aOvUxg1l3lFxoZVRTSmsEeD09xbfZIMEQyEnuHU2MPF6steaBDkLETcx3Ac8+fVw91AaPGs9SX2ZVvJ2uRgvPg5CLblYWi5yKWNLyksaEffqdPgJa5CcVfZmlnbHkYNaxNM2Yd7S42I09nz1guDHByamyuCefmGyfT//RHi5XVIOKpMQRNKRVMQBc5ElU/JK5xx3tUGytsL9HPqZ/j0QkLhkS5I1iKSMjwKTASVp/SWOW10lSRZLn3lQizldLuWEQt4mdMxKJ+Z+wkQubXjecJ9OcEmKKcxu28LoiJn5S6f+jhLzzjnBoh2nV2ha7npP8OOmBV1AL2p6C5sj/cDo9uCLgZ+fPRx/fCQfKORtwo1HkrlXgppXhBWRWr8z3v490obU2dQeCRK3VnGfv2ymWyVMzI+9pl1I/+bfA3/9Ll3gyjbO3L/PpLXPJwJaq3XMsn/92m1Td0/jo8Df/oEupRtEUAcgYOYFMmgeSbZwsbMNiWpG0Yp/4S4sRC/uFziteOeV4GITydI9V9e4sSHMyo8K12zF9Dk2uoHNDu6+jhfzColkibrLKSqBqq4waoXMwMaFseba6f5uV1EqNm6OIIrKToyqKAnYi7mN733OycDl3w5/nzd3ACrgIigN3WItD2KtIzR0rRsmISWHQl4Q/vjeMpYVsLE4T78QeH6PWXzjvK8kZVvL0NnGVU2WuIuojS5g9admLiCbLPI8QwaTXpAp6smofBnbMjDYQOoElUEpp5hHEVZeNW5o2ws/it6mivW2u+fabRc3ImbyDZ0562XPeoXDTOQZ991/IKGYT06V4QUYr54WxpFb4kLEy4op8sEKiR+Stvjs4Me75+lFvwGla6KURcRH+u2E19ZHDuj3OH9ZsvG89LS+gwqyxsWiL6hr+g8kK7/byvNPZFO2uF2gRW5LTUUcCI58sKZpXc5eAKzdaie+H3u86V7ZA3SfGGx5e1aedAAX/1Vxon5Lt7aIw0i6oOctDCd2TwSgJvTaRxF1U1rDGgG7uWslrruNTEEfuSWuSrSWza1iikJZcy3wyH8BkGDRLG3HH5OwJQ3RS0redcrTxs/PQICT3hqvfntW2F6syvb9KBtc7EyJCyEv40lqKm3rjdXF+45jrUces6FTz7Mm6n1LB3DTsWzHkLRSpQlpAG9ZW3x2pknUGX8eDYU8Ja4rBpaFoPflfaGyaBRhY63bWm+LzgSu3udubIC5FnsrcWK9XeHcWodupL3qE+7KKSRhe68uizB/KUXcBgq5A+rWocgUdjigwisArtig26e58OuaWrfFuYi4+hzK2vLNI+sOTHHvnEj+UMjJDG6dE7zQuX5nvOxNFx1rgJnWehzXQljDCBvKLOK2NdLX70zfZMKjLG4YMh0KOZlBkHgtOjM8fT9KzFy2c/OyOL/6u/bRD0kEPUrEi/Td2rpUGp3AZt8cDfcB+74JTLyB1BfZMrhhCIWc+DC1Z5u9wE32podLa30yxuKiv7SAiSgRL9KVEqcmjk1ET5KM2iCkA/hXZwEXf7H4aJh2g0JOphE3wSmsA70tRTRfjhL0PDscxSHu4mbcsbr8LOiGyQ8KOZlG3GJHWYT8jfQDj90OTBxxv+9phNT1CJqHIuu6JFnQ7DwBuCFlmKLLBh4ds4DzPpm9G+Z42d2f6/IIVSvpkAQKOTlOWNf7IPKwTPOy1oMqFLaKZxWjUjY+6t7F4bL5dRbRMJELwAKc+o761W+hkJPjxHGr2PqaXePKtx5EnNrheZJUyLO++Di9yDrKNn14K/D96+O9Jm3GcRmgkJPj2ApGWQQvC2u9jDkAZRVyPy7dMEnF1TYkM4qqxc5nKuQicieA9QB+qZQ6K2p7CnlxxFlEK6PYAfUtlwDEf295158JwqUbJk6Y4/gosOtC4I1X0x+3lbQ5CVmStZC/C8CrAO6mkJcbW7dKFn5XF7iqFFhWIfewFfSyvQ/Xd082HaHiNJBOSlnqpWfuWhGRXgC7KeTlxkYgsqhh4oqg8Xd0Azc2e1Ta3PaXTfz82NR78Yh6L8N9upzCGRcV4xt2KrIhvUP97FoX3gzFBUXcDRUu5CKyCcAmAFi6dOk5+/cbCnmQzLB1q5RZ6IKE3HT30JriX+bbZT+u6swEfd4u8gHS4HIRO06Y49iQu/IFRnKozFm4kLdCi7wYylxPxJag91D2McchrFhZEGHv/dZZwESQJZxTKWAbnAm7ACf+a+CCQXsrOcvIKA/XF04KOYkU8qKtNRvqLuSxFjsFGAgRoVtmhbs0yjZvTq3mGG6Y1uPff5WbaBwTae8M2Xy5zRnuC39eOsov4nVn28KYL4gQ4rd/MNyVNijlauZwzqbp1nQqP7fSr/UujNIBnHV5+DnuPz7grj6Nx5GDekyu/etOhFxEvgbgAgCLROQ5AANKqa+42DdxQ5RvPOtuN0STR4SFhydaYZ/9of1aWMpmnQPTrenj6fjPJduXmtDz4M1F9zy7lP6gSBUX4a9emWhXYs6EoDYh7OQrKnszCVV2rcQtjWCD7Xu3EZ8quNY8XNfpsQlzNBF3XcMjSacpulbamF3rzM91zqmOiFedfcPFHXtARbsJ9t6rF//KshAaxtpt08/btAuXrzw3PVM0jsspaDsbcV9+meXgLKBFjvq1cPNT1lKtSXBhkQdZc3mkaru2yJN+dnWzzoNw7dtOmxDUupAqncDFO5Kda6y1YsB0UldN4EwMdsBopZQhvTsOW+cFRzR4n5WLrMKs58SljzzNOWrTRq/Icr4uySKGvKhFYgq5gTpZq37CEoA65wA3HM53PGnII1MPSOa3TIPpFtym/2ba83NsyNyb1aNjFnBj1vXicyZu0444ZJ14Rh95Asq6mm9L2MlaJhHPujt8HFz6LW0I9KPKVChcnHZvcfGOETb/E6/r56vuavHIUsSBqfDCvDOJG/kdqpxECfWglEtobAkb8/qd+Y0jirLMbces/F1N23uDH1/zn6b+Nta8cThvA0r7gMPYe2+COPcSMTakz7UsRbyVIwfznS9a5NAncpSgVN06b6VKfvG8mHhduxl2XwktkgrOmiCYMEU12EQRrfiQ27F4C3lh1SWzSmbJmlu6gck37Lb1v7c0i6Z59qalkDepk5iHvo+SWMClRk39fulpQwODlCK/Y3nw42uunf6/yWrPys3RfyDa/bD7SuCx7eWtkOkRJ77bFJXifyxOGv/sBXbHdkHbL3b6qXphqSgLooy+Tps5j+rUnjbzzykWIm8bLVVkVNWts/WdiolGF7A5hwzVuMQRcJfRJ613M1n5yBm1EoMoYSmzkFd57FmRV2PntARdZIsOj7VZbC2TcWAr4lUqa9wKo1Zi4H1JyrIQ5wpp06XtoGJIHoEi7/nIc2bvvboJRJkE5up9zTDFj8M4J2Ua96GfhT9f1ruItNAij6BqWZ9hrpUq1VQpA1nURnFCRPnarLDpXFT0QmiYRV702FxA10obYcraK/tFyMT2Xm1pzV+afzadqSSAy07ySSiqh6TNxa3o0rh+MS9Lv00XUMjbiCDxkY5qlqoNsrDytKyS1HbJS+SLFCibFH/eAbrHJORt6jVtP87/s6JHkIyg2+TdV5Y7OeXSe/RFc0BN/3HNCz9yv09bbjisyxmE8chndX0ckj0U8pphik+uqmXUMSv4cS85pSps6Ql+fPaCKaGPG3e8+Oz040rDFQ/oxtdhi+hHXwFuZkhF5lDIa0ZQqFijK/9xuOKi28OfHxS9wFt2TG6I1kiP/gP2FnxZ/L5LVgM3TYRfhNREtS66VYRC3gas/lTRI9AhbNsWTtWuGWwAt5+hE3nCOGdTdG2Y55/QERVlxWSNz1+WbH8Dqhwi3kr/AR1PHgbFPDu42GmgzC3FWsfWOiZT6FXR47YplwoAJ70tWTakRxb1s12cB0mTekyvK3ssdJ1LQxcNE4JiYDoRi86yCxqD9/+AChbxRnf2Y4pi37fstvPXNfF37RlQ4QWQDr8wfT7KwHBf8ONR/vAwd5FtAaiiePefA9+/vuhRtBcUcgeUUeA93v+X+Y3BxPLLkjWFOHKwpSIhtPi9/wvA/h9GlyMtS4Gzn34v+PGoLEiXbcrypvcCFJYd267QR54hZfAJPvznRY9gys+dthqcJ/zP8g4AAAvMSURBVOx770VlqjiecdHMx/KsilcES1YDGx8BTjpj+uNluLDWlcpZ5HmkzNuUtK0KUbUn8sJf7yR10kxFRMErJuXdQVS1WFNclqwG/vQnRY+ifajUYmcRlf3SCnpZxlR2ayiLbMjOE4BVn0gXQ1/UojerWJIgapGiH0fAsj7Ry1C3PK6gV+nLn4Wwd8wCzvtkPGEvav2DQk6CaDsh9yjiC5f3l8x2XtKOyxT2mAdFCfvNneZjZjUHNnVMKOTtSS1qrSQ5ebP2dfvHVMQXzMsEzDKD0xT2mBet9UtcMfG6rgfiJSndOltX92vljx82v95UDiEtUSJeV+5YNZUstmtd0aOpFpVb7CzjQmRZrCMvSSSo1GhZxpiWwQ7zc41uYDJFoown7I98VtcPOeuP9AVkzbXBpVujOudkRqXMLzum1dFXOlx1xvdcgFPfUb6s1jJQOSEHpotS2US9DKzdVt0iWWFs6QFgaKjgv1CN9AOj25MLu5rUkSZP3acr/Y19uSSt4hrAQEE10LPEqpKj0mIfJPCnv9fcz7UdqKSQt9L6BQ7qjlMXS7Td2bbQ7HLY+OjMx/wXs6TCfuw1LRwmqzxP6nwuLz47RRKUyYJH8U0u8qLyQt5KUbdcRS4C5kHRdz07lput4RUbzLVZWvEL+/go8Ld/ALzynN0YihbxzjnFHj9rPvZ4eJvCpBzaH3z+1i2e34mQi8j7APxXAB0AvqyU+gsX+60CQYuAdRTzohjuM/uiF52ZvHv7ktXAp8en/h8bAh78jK6fHYfWz3/RmbpZcVpmL5h54brhcPr9lh3PENu1DnjmIWSa9GWqZ19VgU8dfigiHQB+AuC9AJ4D8I8A/kgpZTylq1D90IYy1FjJg6D3mUcFvvHR6UW0WsnyC7djuZuFTOkELt6RrC3dtoVabKoqLFmQh8CbKMvnkFkcuYisBvCflVLrmv9fBwBKqa2m11DIq0XZshvzuIjYlt6NiyurnUyRl8CXQcyzLGP7ZgAtN6l4DkAFerZkRA1Dw4ogzC+fRy1urzaMK+vc41dPTX9vZRCHqmOKVvHualxRiqglA7ktdorIJgCbAGDp0qV5HTYzjNZ4zULDiljoDOvxmPfdztX7tIvnqxeki1E3EeSrLUsbt6pjukDaZM4GUeaqlS6E/OcAlrT8f1rzsWkopYYADAHateLguKSGbFtoTokPCjPMgyWrgc2vm11Mw33R9dHj4I+V7p4LXPeyu/23O6aF4zCBL/udkwsh/0cAZ4jIW6AF/HIAH3KwX1JSuudms18XYYZFcOk9M6NnbjtFdyxywdFXaLXnQZUjg1ILuVLqmIj8RwAPQIcf3qmU+nHqkVWQui1ymsjCOty1zuyLnr8seZhhUfh7h9JqJ1nixEeulPougO+62BdpP8ZHza3guufWIzOv1WrftS5Z67swZljtAqz4UPUugCQZtcrsJHbYdlnKa6HTFCve6KqnlZm0h2kslL4D8N8F0CVTTyjkCfFXYayKWyVInPNon2ei6DDDIvAShEauyz+kLbDoVAvtUpukblDIU1AV8Y5L1Bfd2XFCYu7rOrce/h6mgE5CKkLcWzHVJvFIk61KsqNSHYJIejJ1lzSAk04HLrk7OsIkbBxlFfEiu0GVQeRtofsmO7LM7CQVItPGHJPAS0+bfd42rLnW3XDqRJAF7zE+Ctx/FfDij4HJN/IdVxBR7puexTOjekg6KORtSBm7LAG6DkkdG2JkzZLVwMf/yfy861T1tBx+Ifr8W7GBETdxoJC3KWXrsjR7AYtJZUVYRmLZRN4jKOKmlbJnWuYNhZwE+nkDxb0BY6u1tFThS9mzeHq2Zs/i4sbiirB5396rFz8BLZyz5k79XzSmeuIe7Sb0XOwkzhjuA578urlWiomyLm4G4aXe0887E9fZq66ok6hnVo88CRRyQtqP8VHgrncDE0fyP3ZdxJxRK4SQQlmyGrjxN+HbDHYgE/ddGdcBXEIhJ8SSkX5g3zCw/FJG12RFVD3/pIuzZa4l7gIKOSEWjPQDj3xW/+39ppjnj417xC/2dXGrhEEhJ8SCRz43838KeTmpu2gHwQ6ThNjgjwmoUKQNqT8UckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTgUckIIqTiphFxEPigiPxaRSRFZ6WpQhBBC7ElrkT8J4FIAP3QwFkIIIQlI1XxZKfUUAIiIm9EQUkLGhooeASHh5OYjF5FNIrJHRPa8+OKLeR2WkNTsvrLoERASTqRFLiIjABYHPHWDUurbtgdSSg0BGAKAlStXsgc5IYQ4IlLIlVJr8xgIIVVigKYIKREMPySEkIqTNvzwEhF5DsBqAPeLyANuhkUIIcSWtFEr9wG4z9FYCCGEJICuFUIIqTgUckIIqTgUckIIqTgUckIimL0g/H9CioZCTkgE/QemxHv2Av0/IWUiVdQKIe0CxZuUGVrkhBBScSjkhBBScSjkhBBScSjkhBBScSjkhBBScSjkhBBScUSp/Asri8iLAPZntPtFAH6V0b5dUYUxAtUYZxXGCHCcLqnCGIFsxrlMKXWy/8FChDxLRGSPUmpl0eMIowpjBKoxziqMEeA4XVKFMQL5jpOuFUIIqTgUckIIqTh1FPKhogdgQRXGCFRjnFUYI8BxuqQKYwRyHGftfOSEENJu1NEiJ4SQtoJCTgghFaeSQi4id4rIL0XkScPzIiK3i8jTIvK/ReTsEo7xAhE5JCL/3Py5Ke8xNsexRER+ICL7ROTHIvLJgG0KnU/LMRY+nyIyW0SeEJH/1RznYMA2s0Tkb5pz+biI9JZ0nB8VkRdb5vM/5D3O5jg6ROSfRGR3wHOFz2XLWMLGmf1cKqUq9wPgXQDOBvCk4fn3A/geAAFwHoDHSzjGCwDsLsFcngLg7ObfcwH8BMDyMs2n5RgLn8/m/JzY/LsLwOMAzvNtcxWALzX/vhzA35R0nB8F8IUi57M5jk8D+G9Bn20Z5tJynJnPZSUtcqXUDwEcDNnk9wDcrTSPAXiTiJySz+g0FmMsBUqpXyilftT8+xUATwF4s2+zQufTcoyF05yfV5v/djV//NEEvwfgrubf3wTwHhGRnIYIwHqchSMipwG4GMCXDZsUPpeA1Tgzp5JCbsGbAYy3/P8cSvjFB7C6eXv7PRF5e9GDad6a/g60hdZKaeYzZIxACeazeYv9zwB+CeAhpZRxLpVSxwAcArAw31FajRMALmu60r4pIktyHiIAbAdwLYBJw/OlmEtEjxPIeC7rKuRV4EfQdRP+LYC/BPDfixyMiJwI4FsArlFKvVzkWExEjLEU86mUmlBK/TaA0wCcKyJnFTGOKCzG+T8A9CqlfgvAQ5iyfHNBRNYD+KVSaizP48bFcpyZz2VdhfznAFqveqc1HysNSqmXvdtbpdR3AXSJyKIixiIiXdACea9Sajhgk8LnM2qMZZrP5hh+DeAHAN7ne+r4XIpIJ4D5AArrCGoap1LqgFLq9ea/XwZwTs5DWwPgAyLyLICvA3i3iNzj26YMcxk5zjzmsq5C/h0AH25GW5wH4JBS6hdFD6oVEVns+fNE5FzozyL3L3RzDF8B8JRS6vOGzQqdT5sxlmE+ReRkEXlT8+8TALwXwL/4NvsOgI80//59AN9XzRWxvLAZp28N5APQ6xK5oZS6Til1mlKqF3oh8/tKqT7fZoXPpc0485jLTtc7zAMR+Rp0lMIiEXkOwAD0gg2UUl8C8F3oSIunAbwG4I9LOMbfB/AnInIMwG8AXJ73SdhkDYArAOxt+kwB4HoAS1vGWvR82oyxDPN5CoC7RKQD+kLyDaXUbhG5GcAepdR3oC9Iu0TkaejF8MtzHqPtOP9URD4A4FhznB8tYJwzKOFcBpL3XDJFnxBCKk5dXSuEENI2UMgJIaTiUMgJIaTiUMgJIaTiUMgJIaTiUMgJIaTiUMgJIaTi/H8ZfdoI7I2DgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIME_STEP = 0.1\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(samples.keys())))\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for v in samples.values():\n",
    "    for traj in v.values():\n",
    "        t = np.arange(0, TIME_STEP * len(traj))\n",
    "        if (len(traj) > 0):\n",
    "            x, y = zip(*traj)\n",
    "        plt.plot(x, y, '.', color=colors[cnt])\n",
    "    break\n",
    "    cnt += 1\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i)\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "    labels.append(dataset[i+target_size])\n",
    "  return np.array(data), np.array(labels)\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "    data.append(dataset[indices])\n",
    "\n",
    "    if single_step:\n",
    "      labels.append(target[i+target_size])\n",
    "    else:\n",
    "      labels.append(target[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lyICXwVAxvW9"
   },
   "source": [
    "# Pre-train a model\n",
    "\n",
    "We load a model that was pre-trained following the TensorFlow tutorial.\n",
    "http://trajnet.stanford.edu/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2EH6MFRdzAwd"
   },
   "source": [
    "## Load the pre-trained model and generate some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 32\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(EMBEDDING_SIZE))\n",
    "model.add(tf.keras.layers.LSTM(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIK674SrtCTm"
   },
   "outputs": [],
   "source": [
    "def load_model(batch_size):\n",
    "  urls = {\n",
    "      1: 'https://storage.googleapis.com/tff-models-public/dickens_rnn.batch1.kerasmodel',\n",
    "      8: 'https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel'}\n",
    "  assert batch_size in urls, 'batch_size must be in ' + str(urls.keys())\n",
    "  url = urls[batch_size]\n",
    "  local_file = tf.keras.utils.get_file(os.path.basename(url), origin=url)  \n",
    "  return tf.keras.models.load_model(local_file, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # From https://www.tensorflow.org/tutorials/sequences/text_generation\n",
    "  num_generate = 200\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "  temperature = 1.0\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(\n",
    "        predictions, num_samples=1)[-1, 0].numpy()\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7026,
     "status": "ok",
     "timestamp": 1570299853908,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "MGAdStJ5wDPV",
    "outputId": "6c2c7892-723c-4bae-feb6-a0968c79685a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What of TensorFlow Federated, you ask? Splay, or Death, that the worst friend) fortately at Calais, that answered her hand he\r\n",
      "was--am I hope, but very bad! As I see\r\n",
      "Herself. Again then, it was his ordital to the drinking-table\r\n",
      "with his \n"
     ]
    }
   ],
   "source": [
    "# Text generation requires a batch_size=1 model.\n",
    "keras_model_batch1 = load_model(batch_size=1)\n",
    "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKMUn-TlgxuP"
   },
   "source": [
    "# Load and Preprocess the Federated Shakespeare Data\n",
    "\n",
    "The `tff.simulation.datasets` package provides a variety of datasets that are split into \"clients\", where each client corresponds to a dataset on a particular device that might participate in federated learning.\n",
    "\n",
    "These datasets provide realistic non-IID data distributions that replicate in simulation the challenges of training on real decentralized data. Some of the pre-processing of this data was done using tools from the [Leaf project](https://arxiv.org/abs/1812.01097) ([github](https://github.com/TalwalkarLab/leaf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "di3nStTDg0qc"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = tff.simulation.datasets.shakespeare.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iiY65Vv4QNK"
   },
   "source": [
    "The datasets provided by `shakespeare.load_data()` consist of a sequence of\n",
    "string `Tensors`, one for each line spoken by a particular character in a\n",
    "Shakespeare play. The client keys consist of the name of the play joined with\n",
    "the name of the character, so for example `MUCH_ADO_ABOUT_NOTHING_OTHELLO` corresponds to the lines for the character Othello in the play *Much Ado About Nothing*. Note that in a real federated learning scenario\n",
    "clients are never identified or tracked by ids, but for simulation it is useful\n",
    "to work with keyed datasets.\n",
    "\n",
    "Here, for example, we can look at some data from King Lear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1570299856956,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "FEKiy1ntmmnk",
    "outputId": "90268902-9128-4ee3-e0e8-918e3b616207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(, shape=(), dtype=string)\n",
      "tf.Tensor(What?, shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Here the play is \"The Tragedy of King Lear\" and the character is \"King\".\n",
    "raw_example_dataset = train_data.create_tf_dataset_for_client(\n",
    "    'THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "# To allow for future extensions, each entry x\n",
    "# is an OrderedDict with a single key 'snippets' which contains the text.\n",
    "for x in raw_example_dataset.take(2):\n",
    "  print(x['snippets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kUnbI5Hp4sXg"
   },
   "source": [
    "We now use `tf.data.Dataset` transformations to prepare this data for training the char RNN loaded above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9kDkmGe-7No7"
   },
   "outputs": [],
   "source": [
    "# Input pre-processing parameters\n",
    "SEQ_LENGTH = 100\n",
    "BATCH_SIZE = 8\n",
    "BUFFER_SIZE = 10000  # For dataset shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "W95Of6Bwsrfc"
   },
   "outputs": [],
   "source": [
    "# Using a namedtuple with keys x and y as the output type of the\n",
    "# dataset keeps both TFF and Keras happy:\n",
    "BatchType = collections.namedtuple('BatchType', ['x', 'y'])\n",
    "\n",
    "# Construct a lookup table to map string chars to indexes,\n",
    "# using the vocab loaded above:\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=vocab, values=tf.constant(list(range(len(vocab))),\n",
    "                                       dtype=tf.int64)),\n",
    "    default_value=0)\n",
    "\n",
    "\n",
    "def to_ids(x):\n",
    "  s = tf.reshape(x['snippets'], shape=[1])\n",
    "  chars = tf.strings.bytes_split(s).values\n",
    "  ids = table.lookup(chars)\n",
    "  return ids\n",
    "\n",
    "\n",
    "def split_input_target(chunk):\n",
    "  input_text = tf.map_fn(lambda x: x[:-1], chunk)\n",
    "  target_text = tf.map_fn(lambda x: x[1:], chunk)\n",
    "  return BatchType(input_text, target_text)\n",
    "\n",
    "\n",
    "def preprocess(dataset):\n",
    "  return (\n",
    "      # Map ASCII chars to int64 indexes using the vocab\n",
    "      dataset.map(to_ids)\n",
    "      # Split into individual chars\n",
    "      .unbatch()\n",
    "      # Form example sequences of SEQ_LENGTH +1\n",
    "      .batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
    "      # Shuffle and form minibatches\n",
    "      .shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "      # And finally split into (input, target) tuples,\n",
    "      # each of length SEQ_LENGTH.\n",
    "      .map(split_input_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jw98HnKmEhuh"
   },
   "source": [
    "Note that in the formation of the original sequences and in the formation of\n",
    "batches above, we use `drop_remainder=True` for simplicity. This means that any\n",
    "characters (clients) that don't have at least `(SEQ_LENGTH + 1) * BATCH_SIZE`\n",
    "chars of text will have empty datasets. A typical approach to address this would\n",
    "be to pad the batches with a special token, and then mask the loss to not take\n",
    "the padding tokens into account.\n",
    "\n",
    "This would complicate the example somewhat, so for this tutorial we only use full batches, as in the\n",
    "[standard tutorial](https://www.tensorflow.org/tutorials/sequences/text_generation).\n",
    "However, in the federated setting this issue is more significant, because many\n",
    "users might have small datasets.\n",
    "\n",
    "Now we can preprocess our `raw_example_dataset`, and check the types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1570300376400,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "7rTal7bksWwc",
    "outputId": "81b09b43-5d30-4250-8c45-eae0928e480e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchType(x=TensorSpec(shape=(8, 100), dtype=tf.int64, name=None), y=TensorSpec(shape=(8, 100), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "example_dataset = preprocess(raw_example_dataset)\n",
    "print(tf.data.experimental.get_structure(example_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePT8Oawm8SRP"
   },
   "source": [
    "# Compile the model and test on the preprocessed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEgDsz-48cAq"
   },
   "source": [
    "We loaded an uncompiled keras model, but in order to run `keras_model.evaluate`, we need to compile it with a loss and metrics. We will also compile in an optimizer, which will be used as the on-device optimizer in Federated Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsuVZ5KMWnn8"
   },
   "source": [
    "The original tutorial didn't have char-level accuracy (the fraction\n",
    "of predictions where the highest probability was put on the correct\n",
    "next char). This is a useful metric, so we add it.\n",
    "However, we need to define a new metric class for this because \n",
    "our predictions have rank 3 (a vector of logits for each of the \n",
    "`BATCH_SIZE * SEQ_LENGTH` predictions), and `SparseCategoricalAccuracy`\n",
    "expects only rank 2 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gOUiDBvmWlM9"
   },
   "outputs": [],
   "source": [
    "class FlattenedCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "\n",
    "  def __init__(self, name='accuracy', dtype=None):\n",
    "    super(FlattenedCategoricalAccuracy, self).__init__(name, dtype=dtype)\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, len(vocab), 1])\n",
    "    return super(FlattenedCategoricalAccuracy, self).update_state(\n",
    "        y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QH6vXHHeWkYN"
   },
   "outputs": [],
   "source": [
    "def compile(keras_model):\n",
    "  keras_model.compile(\n",
    "      optimizer=tf.keras.optimizers.SGD(lr=0.5),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[FlattenedCategoricalAccuracy()])\n",
    "  return keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2X9eFgt94PM"
   },
   "source": [
    "Now we can compile a model, and evaluate it on our `example_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2868,
     "status": "ok",
     "timestamp": 1570300918956,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "c3Xd-52-9zGa",
    "outputId": "47a39e8f-0156-42e0-e5e8-fe5e38bf68a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on an example Shakespeare character:\n",
      "      1/Unknown - 1s 1s/step - loss: 2.9296 - accuracy: 0.4412\n",
      "Expected accuracy for random guessing: 0.012\n",
      "Evaluating on completely random data:\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 11.4698 - accuracy: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.4698486328125, 0.0125]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8  # The training and eval batch size for the rest of this tutorial.\n",
    "keras_model = load_model(batch_size=BATCH_SIZE)\n",
    "\n",
    "compile(keras_model)\n",
    "\n",
    "# Confirm that loss is much lower on Shakespeare than on random data\n",
    "print('Evaluating on an example Shakespeare character:')\n",
    "keras_model.evaluate(example_dataset.take(1))\n",
    "\n",
    "# As a sanity check, we can construct some completely random data, where we expect\n",
    "# the accuracy to be essentially random:\n",
    "random_indexes = np.random.randint(\n",
    "    low=0, high=len(vocab), size=1 * BATCH_SIZE * (SEQ_LENGTH + 1))\n",
    "data = {\n",
    "    'snippets':\n",
    "        tf.constant(''.join(np.array(vocab)[random_indexes]), shape=[1, 1])\n",
    "}\n",
    "random_dataset = preprocess(tf.data.Dataset.from_tensor_slices(data))\n",
    "print('\\nExpected accuracy for random guessing: {:.3f}'.format(1.0 / len(vocab)))\n",
    "print('Evaluating on completely random data:')\n",
    "keras_model.evaluate(random_dataset, steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lH0WzL5L8Lm4"
   },
   "source": [
    "# Fine-tune the model with Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCao4M3L_tsA"
   },
   "source": [
    "TFF serializes all TensorFlow computations so they can potentially be run in a\n",
    "non-Python environment (even though at the moment, only a simulation runtime implemented in Python is available). Even though we are running in eager mode, (TF 2.0), currently TFF serializes TensorFlow computations by constructing the\n",
    "necessary ops inside the context of a \"`with tf.Graph.as_default()`\" statement.\n",
    "Thus, we need to provide a function that TFF can use to introduce our model into\n",
    "a graph it controls. We do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5KadIvFp7m6y"
   },
   "outputs": [],
   "source": [
    "# Clone the keras_model inside `create_tff_model()`, which TFF will\n",
    "# call to produce a new copy of the model inside the graph that it will serialize.\n",
    "def create_tff_model():\n",
    "  # TFF uses a `dummy_batch` so it knows the types and shapes\n",
    "  # that your model expects.\n",
    "  x = tf.constant(np.random.randint(1, len(vocab), size=[BATCH_SIZE, SEQ_LENGTH]))\n",
    "  dummy_batch = collections.OrderedDict([('x', x), ('y', x)]) \n",
    "  keras_model_clone = compile(tf.keras.models.clone_model(keras_model))\n",
    "  return tff.learning.from_compiled_keras_model(\n",
    "      keras_model_clone, dummy_batch=dummy_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJF_yhJxAi2l"
   },
   "source": [
    "Now we are ready to construct a Federated Averaging iterative process, which we will use to improve the model (for details on the Federated Averaging algorithm, see the paper [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629)).\n",
    "\n",
    "We use a compiled Keras model to perform standard (non-federated) evaluation after each round of federated training. This is useful for research purposes when doing simulated federated learning and there is a  standard test dataset. \n",
    "\n",
    "In a realistic production setting this same technique might be used to take models trained with federated learning and evaluate them on a centralized benchmark dataset for testing or quality assurance purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "my3PW3qhAMDA"
   },
   "outputs": [],
   "source": [
    "# This command builds all the TensorFlow graphs and serializes them: \n",
    "fed_avg = tff.learning.build_federated_averaging_process(model_fn=create_tff_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVOkzs9C9kmv"
   },
   "source": [
    "Here is the simplest possible loop, where we run federated averaging for one round on a single client on a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33518,
     "status": "ok",
     "timestamp": 1570300430322,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "lrjUrkjq9jYk",
    "outputId": "a61c592c-641b-49a7-ffc0-988ca7fbcb89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<accuracy=0.016249999404,loss=4.45304775238>\n"
     ]
    }
   ],
   "source": [
    "state = fed_avg.initialize()\n",
    "state, metrics = fed_avg.next(state, [example_dataset.take(1)])\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2CjvVg0FZpS"
   },
   "source": [
    "Now let's write a slightly more interesting training and evaluation loop.\n",
    "\n",
    "So that this simulation still runs relatively quickly,  we train on the same three clients each round, only considering two minibatches for each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wE386-rbMCve"
   },
   "outputs": [],
   "source": [
    "def data(client, source=train_data):\n",
    "  return preprocess(\n",
    "      source.create_tf_dataset_for_client(client)).take(2)\n",
    "\n",
    "clients = ['ALL_S_WELL_THAT_ENDS_WELL_CELIA',\n",
    "           'MUCH_ADO_ABOUT_NOTHING_OTHELLO',\n",
    "           'THE_TRAGEDY_OF_KING_LEAR_KING']\n",
    "\n",
    "train_datasets = [data(client) for client in clients]\n",
    "\n",
    "# We concatenate the test datasets for evaluation with Keras.\n",
    "test_dataset = functools.reduce(\n",
    "    lambda d1, d2: d1.concatenate(d2),\n",
    "    [data(client, test_data) for client in clients])\n",
    "\n",
    "# NOTE: If the statement below fails, it means that you are\n",
    "# using an older version of TFF without the high-performance\n",
    "# executor stack. Call `tff.framework.set_default_executor()`\n",
    "# instead to use the default reference runtime.\n",
    "if six.PY3:\n",
    "  tff.framework.set_default_executor(tff.framework.create_local_executor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cU3FuY00MOoX"
   },
   "source": [
    "The initial state of the model produced by `fed_avg.initialize()` is based\n",
    "on the random initializers for the Keras model, not the weights that were loaded,\n",
    "since `clone_model()` does not clone the weights. To start training\n",
    "from a pre-trained model, we set the model weights in the server state\n",
    "directly from the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 300521,
     "status": "ok",
     "timestamp": 1570300732943,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "vm_-PU8OFXpY",
    "outputId": "2cc442c2-675b-4268-bc15-3b48c10975f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating before training round 0\n",
      "2/2 [==============================] - 1s 649ms/step - loss: 3.2126 - accuracy: 0.4288\n",
      "Training metrics:  <accuracy=0.413541674614,loss=3.30218100548>\n",
      "Evaluating before training round 1\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 2.8153 - accuracy: 0.4588\n",
      "Training metrics:  <accuracy=0.434791654348,loss=2.98462796211>\n",
      "Evaluating before training round 2\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 2.7724 - accuracy: 0.4575\n",
      "Training metrics:  <accuracy=0.437916666269,loss=2.87845301628>\n",
      "Evaluating before training round 4\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 2.7769 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 3\n",
    "\n",
    "# The state of the FL server, containing the model and optimization state.\n",
    "state = fed_avg.initialize()\n",
    "\n",
    "state = tff.learning.state_with_new_model_weights(\n",
    "    state,\n",
    "    trainable_weights=[v.numpy() for v in keras_model.trainable_weights],\n",
    "    non_trainable_weights=[\n",
    "        v.numpy() for v in keras_model.non_trainable_weights\n",
    "    ])\n",
    "\n",
    "\n",
    "def keras_evaluate(state, round_num):\n",
    "  tff.learning.assign_weights_to_keras_model(keras_model, state.model)\n",
    "  print('Evaluating before training round', round_num)\n",
    "  keras_model.evaluate(example_dataset, steps=2)\n",
    "\n",
    "\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "  keras_evaluate(state, round_num)\n",
    "  # N.B. The TFF runtime is currently fairly slow,\n",
    "  # expect this to get significantly faster in future releases.\n",
    "  state, metrics = fed_avg.next(state, train_datasets)\n",
    "  print('Training metrics: ', metrics)\n",
    "\n",
    "keras_evaluate(state, NUM_ROUNDS + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoshvcHhXVa6"
   },
   "source": [
    "With the default changes, we haven't done enough training to make a big difference, but if you train longer on more Shakespeare data, you should see a difference in the style of the text generated with the updated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5795,
     "status": "ok",
     "timestamp": 1570300738815,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "NTUig7QmXavy",
    "outputId": "b25958d5-53c6-406b-87c7-3a2f38803f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What of TensorFlow Federated, you ask? Says it with the knitting.\n",
      "g of a spy, kept from such hopes to a passenger, whom, one. Piploing And my will be a moment!\" said Monsieur Defarge.\n",
      "\r\n",
      "\r\n",
      "There were more than twice, went them, and clieding\n"
     ]
    }
   ],
   "source": [
    "keras_model_batch1.set_weights([v.numpy() for v in keras_model.weights])\n",
    "# Text generation requires batch_size=1\n",
    "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DA1Fkf5mN0s"
   },
   "source": [
    "# Suggested extensions\n",
    "\n",
    "This tutorial is just the first step! Here are some ideas for how you might try extending this notebook:\n",
    "  * Write a more realistic training loop where you sample clients to train on randomly.\n",
    "  * Use \"`.repeat(NUM_EPOCHS)`\" on the client datasets to try multiple epochs of local training (e.g., as in [McMahan et. al.](https://arxiv.org/abs/1602.05629)). See also [Federated Learning for Image Classification](federated_learning_for_image_classification.md) which does this.\n",
    "  * Change the `compile()` command to experiment with using different optimization algorithms on the client.\n",
    "  * Try the `server_optimizer` argument to `build_federated_averaging_process` to try different algorithms for applying the model updates on the server.\n",
    "  * Try the `client_weight_fn` argument to to `build_federated_averaging_process` to try different weightings of the clients. The default weights client updates by the number of examples on the client, but you can do e.g. `client_weight_fn=lambda _: tf.constant(1.0)`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Federated Learning for Text Generation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
